{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Qué es el temporal difference learning y en qué se diferencia de los métodos tradicionales de aprendizaje\n",
    "supervisado? Explique el concepto de \"error de diferencia temporal\" y su papel en los algoritmos de\n",
    "aprendizaje por refuerzo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temporal Difference Learning (TD Learning)** es una técnica de **aprendizaje por refuerzo** que permite a un agente aprender a tomar decisiones basándose en experiencias previas sin necesidad de conocer de antemano todas las recompensas futuras. A diferencia de los métodos tradicionales de **aprendizaje supervisado**, que requieren un conjunto de datos etiquetados y ajustan los parámetros basándose en errores calculados con la respuesta correcta, TD Learning aprende de manera **incremental** mientras interactúa con su entorno, sin esperar el resultado final de una secuencia de acciones. Esto lo hace más eficiente en entornos dinámicos y de aprendizaje continuo, donde los resultados a largo plazo son inciertos.\n",
    "\n",
    "El **error de diferencia temporal (TD error)** es la diferencia entre la estimación actual de la función de valor y una nueva estimación obtenida tras observar la siguiente recompensa y el estado resultante. \n",
    "\n",
    "Este error permite ajustar la función de valor progresivamente, acercándola a la realidad sin necesidad de esperar el desenlace completo de una acción. En algoritmos como **Q-learning y SARSA**, el TD error es fundamental para actualizar los valores de estado-acción, lo que permite que el agente aprenda estrategias óptimas en entornos con incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. En el contexto de los juegos simultáneos, ¿cómo toman decisiones los jugadores sin conocer las acciones\n",
    "de sus oponentes? De un ejemplo de un escenario del mundo real que pueda modelarse como un juego\n",
    "simultáneo y discuta las estrategias que los jugadores podrían emplear en tal situación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los **juegos simultáneos**, los jugadores toman decisiones sin conocer las acciones de sus oponentes, lo que los obliga a basarse en estrategias que maximicen su beneficio sin información completa. Para ello, pueden optar por **estrategias puras**, donde eligen una acción fija, o **estrategias mixtas**, donde asignan probabilidades a diferentes opciones para hacer su decisión menos predecible. En estos juegos, los jugadores suelen analizar los posibles resultados de sus acciones en función de las decisiones que podrían tomar sus rivales, utilizando herramientas como la teoría de juegos, donde cada jugador selecciona una estrategia óptima bajo la suposición de que el otro también lo hará.\n",
    "\n",
    "Un ejemplo real es la competencia entre aerolíneas para fijar precios de boletos. Si American Airlines y Delta deben decidir si bajan sus tarifas sin conocer la decisión de la otra, pueden analizar patrones de precios pasados o alternar entre estrategias para evitar pérdidas y maximizar ganancias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Qué distingue los juegos de suma cero de los juegos de suma cero y cómo afecta esta diferencia al\n",
    "proceso de toma de decisiones de los jugadores? Proporcione al menos un ejemplo de juegos que entren\n",
    "en la categoría de juegos de no suma cero y discuta las consideraciones estratégicas únicas involucradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los **juegos de suma cero** son aquellos donde la ganancia de un jugador equivale exactamente a la pérdida de otro, es decir, lo que uno gana, el otro lo pierde. En estos juegos, los jugadores adoptan estrategias competitivas como **minimax**, tratando de minimizar la máxima ganancia del oponente. Un ejemplo clásico es el **ajedrez**, donde un jugador solo gana si el otro pierde.  \n",
    "\n",
    "En contraste, los **juegos de no suma cero** permiten que ambos jugadores ganen o pierdan simultáneamente, lo que abre espacio para la cooperación. Un ejemplo es la **negociación salarial entre empleados y una empresa**: si llegan a un acuerdo justo, ambas partes pueden beneficiarse (los empleados obtienen mejores salarios y la empresa retiene talento). En estos casos, las estrategias incluyen **cooperación, negociación y repetición de interacciones** para generar confianza y maximizar beneficios conjuntos en lugar de centrarse solo en la competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿Cómo se aplica el concepto de equilibrio de Nash a los juegos simultáneos? Explicar cómo el equilibrio de\n",
    "Nash representa una solución estable en la que ningún jugador tiene un incentivo para desviarse\n",
    "unilateralmente de la estrategia elegida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **equilibrio de Nash** en juegos simultáneos es una situación en la que ningún jugador tiene incentivos para cambiar unilateralmente su estrategia, dado que cualquier desviación empeoraría su resultado o lo dejaría igual. En estos juegos, los jugadores toman decisiones sin conocer las elecciones de los demás y buscan estrategias óptimas asumiendo que los oponentes harán lo mismo.  \n",
    "\n",
    "Un ejemplo es la competencia entre McDonald's y Burger King, que deben decidir si abrir una sucursal en una nueva ubicación sin conocer la decisión del otro. Si ambas abren, obtienen ganancias moderadas debido a la competencia; si solo una abre, esta obtiene altos beneficios mientras la otra no gana nada; y si ninguna abre, ambas pierden la oportunidad de captar clientes. Si el equilibrio de Nash indica que ambas deben abrir, ninguna tiene incentivo para cambiar su decisión, ya que hacerlo reduciría su beneficio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Discuta la aplicación del temporal difference learning en el modelado y optimización de procesos de toma\n",
    "de decisiones en entornos dinámicos. ¿Cómo maneja el temporal difference learning el equilibrio entre\n",
    "exploración y explotación y cuáles son algunos de los desafíos asociados con su implementación en la\n",
    "práctica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **Temporal Difference Learning (TD Learning)** optimiza la toma de decisiones en entornos dinámicos al actualizar valores de estado de forma incremental sin esperar la recompensa final, siendo útil en áreas como tráfico, juegos e inversiones. Para equilibrar **exploración y explotación**, usa estrategias como **ε-greedy** o reducción progresiva de exploración. Sus principales desafíos incluyen la **convergencia lenta**, la **elección del factor de descuento** y la **escalabilidad**, ya que en problemas complejos el cálculo puede volverse costoso."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
